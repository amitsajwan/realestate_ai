"""
Comprehensive Test Runner for Smart Properties
Runs all test suites and provides detailed reporting
"""
import subprocess
import sys
import time
import os
import requests
from datetime import datetime


class SmartPropertiesTestRunner:
    """Main test runner for all Smart Properties test suites"""
    
    def __init__(self):
        self.server_url = "http://127.0.0.1:8003"
        self.test_results = {
            'integration': {'status': 'pending', 'details': []},
            'unit': {'status': 'pending', 'details': []},
            'e2e': {'status': 'pending', 'details': []},
            'performance': {'status': 'pending', 'details': []},
            'manual': {'status': 'pending', 'details': []}
        }
        self.start_time = datetime.now()
    
    def check_server_status(self):
        """Check if the Smart Properties server is running"""
        print("ðŸ” CHECKING SERVER STATUS")
        print("-" * 40)
        
        try:
            # Check server health
            response = requests.get(f"{self.server_url}/", timeout=5)
            server_running = response.status_code == 200
            
            if server_running:
                print("âœ… Server is running")
                
                # Check dashboard
                dashboard_response = requests.get(f"{self.server_url}/dashboard", timeout=5)
                dashboard_ok = dashboard_response.status_code == 200
                
                if dashboard_ok:
                    print("âœ… Dashboard accessible")
                    
                    # Check Smart Properties in dashboard
                    if "Smart Properties" in dashboard_response.text:
                        print("âœ… Smart Properties component found")
                        return True
                    else:
                        print("âŒ Smart Properties component missing from dashboard")
                        return False
                else:
                    print("âŒ Dashboard not accessible")
                    return False
            else:
                print("âŒ Server not responding")
                return False
                
        except Exception as e:
            print(f"âŒ Server connection failed: {e}")
            return False
    
    def run_integration_tests(self):
        """Run the main integration test suite"""
        print("\\nðŸ§ª RUNNING INTEGRATION TESTS")
        print("-" * 40)
        
        try:
            # Run the main test script
            result = subprocess.run([
                sys.executable, "test_smart_properties.py"
            ], capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                self.test_results['integration']['status'] = 'passed'
                print("âœ… Integration tests PASSED")
                
                # Parse output for details
                output = result.stdout
                if "100.0%" in output:
                    self.test_results['integration']['details'].append("All integration tests passed")
                if "Smart Properties implementation is working correctly" in output:
                    self.test_results['integration']['details'].append("Smart Properties fully functional")
                    
            else:
                self.test_results['integration']['status'] = 'failed'
                print("âŒ Integration tests FAILED")
                print(f"Error: {result.stderr}")
                self.test_results['integration']['details'].append(f"Failure: {result.stderr[:200]}")
                
        except subprocess.TimeoutExpired:
            self.test_results['integration']['status'] = 'timeout'
            print("â° Integration tests TIMED OUT")
        except Exception as e:
            self.test_results['integration']['status'] = 'error'
            print(f"âŒ Integration tests ERROR: {e}")
    
    def run_unit_tests(self):
        """Run unit tests using pytest"""
        print("\\nðŸ”¬ RUNNING UNIT TESTS")
        print("-" * 40)
        
        try:
            # Check if pytest is available
            pytest_result = subprocess.run([
                sys.executable, "-m", "pytest", "--version"
            ], capture_output=True, text=True)
            
            if pytest_result.returncode != 0:
                print("âš ï¸ pytest not available, running unit tests manually")
                
                # Run unit tests manually
                result = subprocess.run([
                    sys.executable, "tests/test_smart_properties_unit.py"
                ], capture_output=True, text=True, timeout=60)
                
                if result.returncode == 0:
                    self.test_results['unit']['status'] = 'passed'
                    print("âœ… Unit tests PASSED (manual run)")
                else:
                    self.test_results['unit']['status'] = 'failed'
                    print("âŒ Unit tests FAILED")
                    print(f"Error: {result.stderr}")
            else:
                # Run with pytest
                result = subprocess.run([
                    sys.executable, "-m", "pytest", "tests/test_smart_properties_unit.py", "-v"
                ], capture_output=True, text=True, timeout=60)
                
                if result.returncode == 0:
                    self.test_results['unit']['status'] = 'passed'
                    print("âœ… Unit tests PASSED (pytest)")
                    
                    # Count passed tests
                    output = result.stdout
                    passed_count = output.count(" PASSED")
                    self.test_results['unit']['details'].append(f"Passed {passed_count} unit tests")
                else:
                    self.test_results['unit']['status'] = 'failed'
                    print("âŒ Unit tests FAILED")
                    
        except subprocess.TimeoutExpired:
            self.test_results['unit']['status'] = 'timeout'
            print("â° Unit tests TIMED OUT")
        except Exception as e:
            self.test_results['unit']['status'] = 'error'
            print(f"âŒ Unit tests ERROR: {e}")
    
    def run_e2e_tests(self):
        """Run end-to-end tests"""
        print("\\nðŸŒ RUNNING END-TO-END TESTS")
        print("-" * 40)
        
        try:
            result = subprocess.run([
                sys.executable, "tests/test_smart_properties_e2e.py"
            ], capture_output=True, text=True, timeout=180)
            
            output = result.stdout
            
            if "API tests completed" in output:
                self.test_results['e2e']['status'] = 'passed'
                print("âœ… E2E tests PASSED")
                
                if "Property Lifecycle: PASSED" in output:
                    self.test_results['e2e']['details'].append("API lifecycle tests passed")
                if "Error Handling: PASSED" in output:
                    self.test_results['e2e']['details'].append("Error handling tests passed")
                if "ChromeDriver" in output:
                    self.test_results['e2e']['details'].append("Browser tests skipped (ChromeDriver not available)")
                    
            else:
                self.test_results['e2e']['status'] = 'failed'
                print("âŒ E2E tests had issues")
                if result.stderr:
                    print(f"Error: {result.stderr[:200]}")
                    
        except subprocess.TimeoutExpired:
            self.test_results['e2e']['status'] = 'timeout'
            print("â° E2E tests TIMED OUT")
        except Exception as e:
            self.test_results['e2e']['status'] = 'error'
            print(f"âŒ E2E tests ERROR: {e}")
    
    def run_performance_tests(self):
        """Run performance tests"""
        print("\\nðŸš€ RUNNING PERFORMANCE TESTS")
        print("-" * 40)
        
        try:
            result = subprocess.run([
                sys.executable, "tests/test_smart_properties_performance.py"
            ], capture_output=True, text=True, timeout=300)  # 5 minutes timeout
            
            output = result.stdout
            
            if "PERFORMANCE TESTING COMPLETE" in output:
                self.test_results['performance']['status'] = 'passed'
                print("âœ… Performance tests COMPLETED")
                
                if "Excellent performance" in output:
                    self.test_results['performance']['details'].append("Excellent performance metrics")
                elif "Good performance" in output:
                    self.test_results['performance']['details'].append("Good performance metrics")
                elif "Acceptable performance" in output:
                    self.test_results['performance']['details'].append("Acceptable performance metrics")
                    
                if "All requests handled successfully" in output:
                    self.test_results['performance']['details'].append("Concurrent load handled well")
                    
            else:
                self.test_results['performance']['status'] = 'incomplete'
                print("âš ï¸ Performance tests incomplete")
                
        except subprocess.TimeoutExpired:
            self.test_results['performance']['status'] = 'timeout'
            print("â° Performance tests TIMED OUT")
        except Exception as e:
            self.test_results['performance']['status'] = 'error'
            print(f"âŒ Performance tests ERROR: {e}")
    
    def run_manual_verification(self):
        """Run manual verification checklist"""
        print("\\nâœ‹ MANUAL VERIFICATION CHECKLIST")
        print("-" * 40)
        
        manual_checks = [
            {
                'name': 'Dashboard Navigation',
                'description': 'Smart Properties tab visible and clickable',
                'test': self._check_dashboard_navigation
            },
            {
                'name': 'API Endpoints',
                'description': 'All Smart Properties API endpoints responding',
                'test': self._check_api_endpoints
            },
            {
                'name': 'AI Content Generation',
                'description': 'AI content generates for new properties',
                'test': self._check_ai_generation
            },
            {
                'name': 'Data Persistence',
                'description': 'Properties persist between requests',
                'test': self._check_data_persistence
            }
        ]
        
        passed_checks = 0
        
        for check in manual_checks:
            try:
                result = check['test']()
                if result:
                    print(f"   âœ… {check['name']}: PASS")
                    passed_checks += 1
                    self.test_results['manual']['details'].append(f"{check['name']}: PASSED")
                else:
                    print(f"   âŒ {check['name']}: FAIL")
                    self.test_results['manual']['details'].append(f"{check['name']}: FAILED")
            except Exception as e:
                print(f"   âŒ {check['name']}: ERROR - {e}")
                self.test_results['manual']['details'].append(f"{check['name']}: ERROR")
        
        if passed_checks == len(manual_checks):
            self.test_results['manual']['status'] = 'passed'
        elif passed_checks >= len(manual_checks) * 0.75:
            self.test_results['manual']['status'] = 'mostly_passed'
        else:
            self.test_results['manual']['status'] = 'failed'
        
        print(f"   ðŸ“Š Manual checks: {passed_checks}/{len(manual_checks)} passed")
    
    def _check_dashboard_navigation(self):
        """Check dashboard navigation works"""
        try:
            response = requests.get(f"{self.server_url}/dashboard", timeout=5)
            return response.status_code == 200 and "Smart Properties" in response.text
        except:
            return False
    
    def _check_api_endpoints(self):
        """Check API endpoints are accessible"""
        try:
            # Check without auth (should get 401)
            response = requests.get(f"{self.server_url}/api/smart-properties/", timeout=5)
            return response.status_code == 401  # Expected for auth-required endpoint
        except:
            return False
    
    def _check_ai_generation(self):
        """Check AI generation functionality"""
        try:
            import base64
            import json
            
            # Create auth token
            payload = {'user_id': 'manual-test', 'email': 'manual@test.com'}
            header = base64.urlsafe_b64encode(json.dumps({'typ': 'JWT'}).encode()).decode().rstrip('=')
            payload_encoded = base64.urlsafe_b64encode(json.dumps(payload).encode()).decode().rstrip('=')
            token = f'{header}.{payload_encoded}.sig'
            
            headers = {'Authorization': f'Bearer {token}'}
            
            # Try to create a property
            property_data = {
                "address": "Manual Test Street, Mumbai",
                "price": "â‚¹2.0 Crore",
                "property_type": "apartment",
                "auto_generate": True
            }
            
            response = requests.post(
                f"{self.server_url}/api/smart-properties",
                json=property_data,
                headers=headers,
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                return 'ai_content' in data and len(data.get('ai_content', '')) > 50
            return False
        except:
            return False
    
    def _check_data_persistence(self):
        """Check data persistence works"""
        try:
            import base64
            import json
            
            # Create auth token
            payload = {'user_id': 'persistence-test', 'email': 'persist@test.com'}
            header = base64.urlsafe_b64encode(json.dumps({'typ': 'JWT'}).encode()).decode().rstrip('=')
            payload_encoded = base64.urlsafe_b64encode(json.dumps(payload).encode()).decode().rstrip('=')
            token = f'{header}.{payload_encoded}.sig'
            
            headers = {'Authorization': f'Bearer {token}'}
            
            # Get properties (should include demo properties at minimum)
            response = requests.get(
                f"{self.server_url}/api/smart-properties/",
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                properties = response.json()
                return isinstance(properties, list) and len(properties) >= 0  # At least demo properties should exist
            return False
        except:
            return False
    
    def generate_report(self):
        """Generate final test report"""
        end_time = datetime.now()
        duration = end_time - self.start_time
        
        print("\\n" + "=" * 70)
        print("ðŸ“‹ COMPREHENSIVE SMART PROPERTIES TEST REPORT")
        print("=" * 70)
        
        print(f"ðŸ• Test Duration: {duration.total_seconds():.1f} seconds")
        print(f"ðŸ—“ï¸ Test Time: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%H:%M:%S')}")
        
        print("\\nðŸ“Š TEST SUITE RESULTS:")
        print("-" * 40)
        
        total_suites = len(self.test_results)
        passed_suites = 0
        
        for suite_name, results in self.test_results.items():
            status = results['status']
            status_icon = {
                'passed': 'âœ…',
                'mostly_passed': 'ðŸŸ¡',
                'failed': 'âŒ',
                'timeout': 'â°',
                'error': 'ðŸ’¥',
                'incomplete': 'âš ï¸',
                'pending': 'â³'
            }.get(status, 'â“')
            
            print(f"   {status_icon} {suite_name.upper()}: {status.upper()}")
            
            if results['details']:
                for detail in results['details'][:3]:  # Show first 3 details
                    print(f"      â€¢ {detail}")
            
            if status in ['passed', 'mostly_passed']:
                passed_suites += 1
        
        success_rate = (passed_suites / total_suites) * 100
        
        print(f"\\nðŸŽ¯ OVERALL RESULTS:")
        print(f"   Test Suites Passed: {passed_suites}/{total_suites}")
        print(f"   Success Rate: {success_rate:.1f}%")
        
        if success_rate >= 90:
            print("   ðŸŽ‰ EXCELLENT - Smart Properties ready for production!")
            print("\\nâœ… PRODUCTION READINESS: HIGH")
            print("   - All critical functionality tested")
            print("   - Performance metrics acceptable")
            print("   - Error handling verified")
            print("   - User workflows validated")
        elif success_rate >= 75:
            print("   âœ… GOOD - Smart Properties mostly ready, minor issues")
            print("\\nðŸŸ¡ PRODUCTION READINESS: MEDIUM")
            print("   - Core functionality working")
            print("   - Some non-critical issues present")
            print("   - Performance acceptable")
        else:
            print("   âŒ NEEDS WORK - Critical issues found")
            print("\\nâŒ PRODUCTION READINESS: LOW")
            print("   - Critical functionality issues")
            print("   - Fix required before production")
        
        print(f"\\nðŸ”— TEST ENVIRONMENT:")
        print(f"   Server: {self.server_url}")
        print(f"   Login: http://localhost:8003/ (demo@mumbai.com / demo123)")
        print(f"   Dashboard: http://localhost:8003/dashboard")
        
        return success_rate


def main():
    """Main test runner function"""
    print("ðŸ§ª SMART PROPERTIES COMPREHENSIVE TEST SUITE")
    print("=" * 70)
    print("Testing all aspects of Smart Properties implementation")
    print("This includes integration, unit, E2E, performance, and manual tests")
    print("=" * 70)
    
    runner = SmartPropertiesTestRunner()
    
    # Step 1: Check server status
    if not runner.check_server_status():
        print("\\nâŒ TESTING ABORTED: Server not ready")
        print("   Please ensure the server is running on http://localhost:8003")
        print("   Run: python -m uvicorn app.main:app --reload --port 8003")
        return
    
    # Step 2: Run all test suites
    runner.run_integration_tests()
    runner.run_unit_tests()
    runner.run_e2e_tests()
    runner.run_performance_tests()
    runner.run_manual_verification()
    
    # Step 3: Generate final report
    success_rate = runner.generate_report()
    
    # Exit with appropriate code
    sys.exit(0 if success_rate >= 75 else 1)


if __name__ == "__main__":
    main()
